{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EHxK0c14nqBJ"
   },
   "source": [
    "# **Are You the Asshole? Judging r/AITA Drama with NLP and ML**\n",
    "*Final Project for CMSC176: Natural Language Processing* </br> </br>\n",
    "**Authors**: \n",
    "- Igot, Leanne Gabrielle \n",
    "- Lahaylahay, Dunn Dexter\n",
    "- Molanda, Clelia \n",
    "- Peladas, Daenielle Rai </br>\n",
    "</br>\n",
    "\n",
    "\n",
    "**Last Modified**: December 8, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ROs6SrCwnqBP"
   },
   "source": [
    "## **Data Acquisition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vVOVGbnwnqBQ",
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/c/Users/gloss/Documents/5th Year (2024 - 25)/1st Sem (5)/CMSC 176 A/Final Project/AITAH-FAFO/notebooks'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Djnq6Ch9nqBS"
   },
   "source": [
    "This function generates a DataFrame from all the scraped comments stored in the specified directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Ff1HHyLfnqBS"
   },
   "outputs": [],
   "source": [
    "def create_dataframe_from_comments():\n",
    "    # Directory path where the JSON files are stored\n",
    "    comments_dir = os.path.join('/mnt/c/Users/gloss/Documents/5th Year (2024 - 25)/1st Sem (5)/CMSC 176 A/Final Project/AITAH-FAFO/scrapes/all-comments') # Change this to your current working directory\n",
    "\n",
    "    # Initialize a list to hold the data\n",
    "    data = []\n",
    "\n",
    "    # Go through all files in the directory\n",
    "    for filename in os.listdir(comments_dir):\n",
    "        if filename.endswith('.json'):\n",
    "            file_path = os.path.join(comments_dir, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                # Load the JSON file\n",
    "                content = json.load(file)\n",
    "\n",
    "                metadata = content['data']['submission_metadata']\n",
    "                comments = content['data']['comments']\n",
    "\n",
    "                # Extract the required fields\n",
    "                title = metadata['title']\n",
    "                selftext = metadata['selftext']\n",
    "                aitah_tag = count_YTA_NTA(comments)\n",
    "\n",
    "                # Append to the data list\n",
    "                data.append({'title': title, 'selftext': selftext, 'aitah_tag': aitah_tag})\n",
    "    # Create a DataFrame from the data\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6p3249mbnqBS"
   },
   "source": [
    "This function analyzes the comment section to count occurrences of keywords related to 'You're the Asshole' (YTA) and 'Not the Asshole' (NTA). Based on the keyword counts, it determines the overall judgment of whether the subject is considered the asshole or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "E1Bko3YJnqBT"
   },
   "outputs": [],
   "source": [
    "def count_YTA_NTA(comments_list):\n",
    "    # Extract 'body' content from each comment\n",
    "    bodies = [comment['body'] for comment in comments_list if 'body' in comment]\n",
    "\n",
    "    # Initialize counters for YTA and NTA\n",
    "    YTA = 0\n",
    "    NTA = 0\n",
    "\n",
    "    # Loop through each comment body and count occurrences of YTA and NTA (including YTAH and NTAH)\n",
    "    for body in bodies:\n",
    "        YTA += len(re.findall(r'\\bYTA\\b', body)) + len(re.findall(r'\\bYTAH\\b', body))\n",
    "        NTA += len(re.findall(r'\\bNTA\\b', body)) + len(re.findall(r'\\bNTAH\\b', body))\n",
    "\n",
    "    if YTA > NTA:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "xZF1PDMQnqBU"
   },
   "outputs": [],
   "source": [
    "# Specify the root directory\n",
    "root_directory = 'AITAH-FAFO'\n",
    "df = create_dataframe_from_comments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "_8Ct30bRnqBV",
    "outputId": "4688e84f-c700-4dec-ed02-9ded32db22fc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>aitah_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AITA for not inviting my mom to my wedding be...</td>\n",
       "      <td>I (28M) am getting married in a few months to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIT for telling my parents something my friend...</td>\n",
       "      <td>I've told this story in a few other subreddits...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AITA -</td>\n",
       "      <td>throw away account so no one sees..\\n\\nMy \\[24...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AITA - my 20 year old flatmate asks me questio...</td>\n",
       "      <td>For context I’m 33; and my flatmate is 20.\\nSh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AITA - my husband never let's me sleep in, so ...</td>\n",
       "      <td>As the title states, I wake my husband up ever...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   AITA for not inviting my mom to my wedding be...   \n",
       "1  AIT for telling my parents something my friend...   \n",
       "2                                            AITA -    \n",
       "3  AITA - my 20 year old flatmate asks me questio...   \n",
       "4  AITA - my husband never let's me sleep in, so ...   \n",
       "\n",
       "                                            selftext  aitah_tag  \n",
       "0  I (28M) am getting married in a few months to ...          0  \n",
       "1  I've told this story in a few other subreddits...          0  \n",
       "2  throw away account so no one sees..\\n\\nMy \\[24...          0  \n",
       "3  For context I’m 33; and my flatmate is 20.\\nSh...          0  \n",
       "4  As the title states, I wake my husband up ever...          0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rmAP-By4nqBW"
   },
   "source": [
    "### **Basic Insights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ArafzqcnqBW",
    "outputId": "8df710b9-3876-486a-cced-34b6c28949f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 574 entries, 0 to 573\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   title      574 non-null    object\n",
      " 1   selftext   574 non-null    object\n",
      " 2   aitah_tag  574 non-null    int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 13.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mA4E_ESinqBW"
   },
   "source": [
    "## **Data Wrangling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicating raw dataset for FastText processing\n",
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "W3dE6kKunqBW",
    "outputId": "55087d39-2331-4196-e8b7-793b244cff21"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title        0\n",
       "selftext     0\n",
       "aitah_tag    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4klH4SJWnqBW"
   },
   "source": [
    "There are no null values shown here. However, there were some posts that were deleted and therefore must be removed since the text in the post itself is necessary for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "mCy2jAJdnqBX"
   },
   "outputs": [],
   "source": [
    "df = df[df['selftext'] != '[deleted]']\n",
    "df = df[df['selftext'] != '[removed]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "slqwcpwMnqBX",
    "outputId": "82834d27-1cb1-4249-bbb6-866ad8c00116"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>aitah_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AITA for not inviting my mom to my wedding be...</td>\n",
       "      <td>I (28M) am getting married in a few months to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIT for telling my parents something my friend...</td>\n",
       "      <td>I've told this story in a few other subreddits...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AITA -</td>\n",
       "      <td>throw away account so no one sees..\\n\\nMy \\[24...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AITA - my 20 year old flatmate asks me questio...</td>\n",
       "      <td>For context I’m 33; and my flatmate is 20.\\nSh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AITA - my husband never let's me sleep in, so ...</td>\n",
       "      <td>As the title states, I wake my husband up ever...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   AITA for not inviting my mom to my wedding be...   \n",
       "1  AIT for telling my parents something my friend...   \n",
       "2                                            AITA -    \n",
       "3  AITA - my 20 year old flatmate asks me questio...   \n",
       "4  AITA - my husband never let's me sleep in, so ...   \n",
       "\n",
       "                                            selftext  aitah_tag  \n",
       "0  I (28M) am getting married in a few months to ...          0  \n",
       "1  I've told this story in a few other subreddits...          0  \n",
       "2  throw away account so no one sees..\\n\\nMy \\[24...          0  \n",
       "3  For context I’m 33; and my flatmate is 20.\\nSh...          0  \n",
       "4  As the title states, I wake my husband up ever...          0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HXAlFiZDnqBX",
    "outputId": "cd74c0ef-7543-46fe-ae8f-044070016427"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 547 entries, 0 to 573\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   title      547 non-null    object\n",
      " 1   selftext   547 non-null    object\n",
      " 2   aitah_tag  547 non-null    int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 17.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aitah_tag\n",
      "0    501\n",
      "1     46\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "a must be greater than 0 unless no samples are taken",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m min_class_size \u001b[38;5;241m=\u001b[39m class_counts\u001b[38;5;241m.\u001b[39mmin()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Undersample the majority class\u001b[39;00m\n\u001b[1;32m     12\u001b[0m df_balanced \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\n\u001b[0;32m---> 13\u001b[0m     \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maitah_tag\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mYTA\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmin_class_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     14\u001b[0m     df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maitah_tag\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNTA\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msample(min_class_size, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     15\u001b[0m ])\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Shuffle the resulting dataframe to ensure randomness\u001b[39;00m\n\u001b[1;32m     18\u001b[0m df_balanced \u001b[38;5;241m=\u001b[39m df_balanced\u001b[38;5;241m.\u001b[39msample(frac\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/pandas/core/generic.py:6118\u001b[0m, in \u001b[0;36mNDFrame.sample\u001b[0;34m(self, n, frac, replace, weights, random_state, axis, ignore_index)\u001b[0m\n\u001b[1;32m   6115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   6116\u001b[0m     weights \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39mpreprocess_weights(\u001b[38;5;28mself\u001b[39m, weights, axis)\n\u001b[0;32m-> 6118\u001b[0m sampled_indices \u001b[38;5;241m=\u001b[39m \u001b[43msample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6119\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(sampled_indices, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m   6121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_index:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/pandas/core/sample.py:152\u001b[0m, in \u001b[0;36msample\u001b[0;34m(obj_len, size, replace, weights, random_state)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid weights: weights sum to zero\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\n\u001b[1;32m    153\u001b[0m     np\u001b[38;5;241m.\u001b[39mintp, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    154\u001b[0m )\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:964\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: a must be greater than 0 unless no samples are taken"
     ]
    }
   ],
   "source": [
    "# Balance dataset\n",
    "import pandas as pd\n",
    "\n",
    "# First, check the counts of each class\n",
    "class_counts = df['aitah_tag'].value_counts()\n",
    "print(class_counts)\n",
    "\n",
    "# Identify majority and minority classes\n",
    "majority_class = class_counts.idxmax()\n",
    "minority_class = class_counts.idxmin()\n",
    "\n",
    "# Calculate the number of samples needed for oversampling\n",
    "samples_to_add = class_counts[majority_class] - class_counts[minority_class]\n",
    "\n",
    "# Oversample the minority class\n",
    "oversampled_samples = df[df['aitah_tag'] == minority_class].sample(\n",
    "    n=samples_to_add, replace=True, random_state=42  # Set random_state for reproducibility\n",
    ")\n",
    "\n",
    "# Add the oversampled instances to the original DataFrame\n",
    "df_balanced = pd.concat([df, oversampled_samples])\n",
    "\n",
    "# Shuffle the resulting dataframe to ensure randomness\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Check the new class distribution\n",
    "print(df_balanced['aitah_tag'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2pUsSMBknqBY"
   },
   "source": [
    "## **Text Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "IeztP3I3nqBZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_m0XazGgnqBZ",
    "outputId": "2d5d604e-8328-4d5f-ff7c-b051eed35c89"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/rx/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/rx/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/rx/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2eooXzlnnqBZ"
   },
   "outputs": [],
   "source": [
    "# Gets a list of english stop words\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "IVtkJtUXnqBa"
   },
   "outputs": [],
   "source": [
    "def preprocess_data(reddit_post):\n",
    "    reddit_post = str(reddit_post).lower()\n",
    "    reddit_post = re.sub(\"[^a-zA-Z0-9\\s]\",'', reddit_post)\n",
    "\n",
    "    temp_final =[]\n",
    "\n",
    "    for word in reddit_post.split():\n",
    "        if word =='' or '\\r\\n' in word or word in stop_words:\n",
    "            None\n",
    "        else:\n",
    "            temp_final.append(word)\n",
    "\n",
    "    return word_tokenize(' '.join(temp_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "oCImDSutnqBc"
   },
   "outputs": [],
   "source": [
    "df['processed_selftext'] = df['selftext'].apply(preprocess_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "1ddGiuqFnqBc",
    "outputId": "faa6f0d3-3594-46b8-9898-e69a7efadbb0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>aitah_tag</th>\n",
       "      <th>processed_selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AITA for not inviting my mom to my wedding be...</td>\n",
       "      <td>I (28M) am getting married in a few months to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[28m, getting, married, months, fiance, sarah,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIT for telling my parents something my friend...</td>\n",
       "      <td>I've told this story in a few other subreddits...</td>\n",
       "      <td>0</td>\n",
       "      <td>[ive, told, story, subreddits, im, gon, na, te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AITA -</td>\n",
       "      <td>throw away account so no one sees..\\n\\nMy \\[24...</td>\n",
       "      <td>0</td>\n",
       "      <td>[throw, away, account, one, sees, 24f, partner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AITA - my 20 year old flatmate asks me questio...</td>\n",
       "      <td>For context I’m 33; and my flatmate is 20.\\nSh...</td>\n",
       "      <td>0</td>\n",
       "      <td>[context, im, 33, flatmate, 20, asks, question...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AITA - my husband never let's me sleep in, so ...</td>\n",
       "      <td>As the title states, I wake my husband up ever...</td>\n",
       "      <td>0</td>\n",
       "      <td>[title, states, wake, husband, every, morning,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   AITA for not inviting my mom to my wedding be...   \n",
       "1  AIT for telling my parents something my friend...   \n",
       "2                                            AITA -    \n",
       "3  AITA - my 20 year old flatmate asks me questio...   \n",
       "4  AITA - my husband never let's me sleep in, so ...   \n",
       "\n",
       "                                            selftext  aitah_tag  \\\n",
       "0  I (28M) am getting married in a few months to ...          0   \n",
       "1  I've told this story in a few other subreddits...          0   \n",
       "2  throw away account so no one sees..\\n\\nMy \\[24...          0   \n",
       "3  For context I’m 33; and my flatmate is 20.\\nSh...          0   \n",
       "4  As the title states, I wake my husband up ever...          0   \n",
       "\n",
       "                                  processed_selftext  \n",
       "0  [28m, getting, married, months, fiance, sarah,...  \n",
       "1  [ive, told, story, subreddits, im, gon, na, te...  \n",
       "2  [throw, away, account, one, sees, 24f, partner...  \n",
       "3  [context, im, 33, flatmate, 20, asks, question...  \n",
       "4  [title, states, wake, husband, every, morning,...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "vwMr33ngnqBd",
    "outputId": "dc986521-ce73-43c6-d61a-ff940c82d610"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aitah_tag\n",
       "0    501\n",
       "1     46\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['aitah_tag'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xqFirjo-q1rN"
   },
   "source": [
    "## **Model Development**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Count Vectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "W1xlMtUPnqBd"
   },
   "outputs": [],
   "source": [
    "#Importing count vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "QvXW2Tw1qT9w"
   },
   "outputs": [],
   "source": [
    "#Creating a CountVectorizer model\n",
    "df['selftext'] = df['processed_selftext']\n",
    "bow_transformer= CountVectorizer(analyzer=preprocess_data).fit(df['selftext'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TA12pfR9qzWi",
    "outputId": "6bc1519f-74a8-429a-cd7a-bf89b037230b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10526\n"
     ]
    }
   ],
   "source": [
    "#Print number of vocabulary/words\n",
    "print(len(bow_transformer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "jkHAiXzPrsVm"
   },
   "outputs": [],
   "source": [
    "article_bow=bow_transformer.transform(df['selftext'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "QWI0n5SErxyf"
   },
   "outputs": [],
   "source": [
    "#Import TFIDF\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "#Making an instance of this transformer\n",
    "tfidf_transformer=TfidfTransformer().fit(article_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gIJXaY7EsLUi",
    "outputId": "1353f18f-cdf3-4e03-a8f7-607d7b56d676"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8995560396837625"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the tfidf of a particular word('husband'), it'll directly error if it doesnt see the word\n",
    "tfidf_transformer.idf_[bow_transformer.vocabulary_['husband']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "DqSWuhVbspS6"
   },
   "outputs": [],
   "source": [
    "#Convert the entire bag of words corpus into a tfidf corpus at once\n",
    "article_tfidf=tfidf_transformer.transform(article_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4FB0tPa8tHQO"
   },
   "source": [
    "### **Support Vector Mac|hine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "_eEiAlRDsw0Z"
   },
   "outputs": [],
   "source": [
    "#lets import SVM\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "selftext_train, selftext_test, aitah_tag_train, aitah_tag_test=train_test_split(df['selftext'],df['aitah_tag'],test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "GzHlB7jKtfG3"
   },
   "outputs": [],
   "source": [
    "#think of the pipeline as the steps or methods on a task\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer(analyzer=preprocess_data)),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf-svm', SGDClassifier(loss='log_loss', penalty='elasticnet',\n",
    "                                            alpha=0.001, random_state=42, class_weight='balanced')),\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "twMxgTaQtkeY"
   },
   "outputs": [],
   "source": [
    "_=text_clf_svm.fit(selftext_train, aitah_tag_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YrrFe8cDtpSp"
   },
   "source": [
    "#### **Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "brnK3drhtsRp"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=text_clf_svm.predict(selftext_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fr-NdXhqLLgm",
    "outputId": "b52b8660-ac40-448d-b041-97964a5381c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set class distribution:\n",
      "aitah_tag\n",
      "0    344\n",
      "1     38\n",
      "Name: count, dtype: int64\n",
      "Test set class distribution:\n",
      "aitah_tag\n",
      "0    157\n",
      "1      8\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the class distribution in the training set\n",
    "print(\"Training set class distribution:\")\n",
    "print(pd.Series(aitah_tag_train).value_counts())\n",
    "\n",
    "# Check the class distribution in the test set\n",
    "print(\"Test set class distribution:\")\n",
    "print(pd.Series(aitah_tag_test).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "xuJDvceKtuET"
   },
   "outputs": [],
   "source": [
    "# Generate a classification report\n",
    "report = classification_report(aitah_tag_test, prediction, zero_division=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "05L5LrHNt0_h",
    "outputId": "03afa38d-e83d-4bf1-a5a5-f489cf1001ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98       157\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.95       165\n",
      "   macro avg       0.48      0.50      0.49       165\n",
      "weighted avg       0.91      0.95      0.93       165\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KPADLlo7t6Cq",
    "outputId": "6aa4e9db-a81e-4be1-affe-b7359b240808"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: NTA\n"
     ]
    }
   ],
   "source": [
    "# Example with manual mapping\n",
    "label_mapping = {0: \"NTA\", 1: \"YTA\"}\n",
    "\n",
    "# Predict the label\n",
    "prediction_numeric = text_clf_svm.predict([\"I gave her flowers\"])[0]\n",
    "prediction_label = label_mapping[prediction_numeric]\n",
    "\n",
    "print(f\"Predicted class: {prediction_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **FastText**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>aitah_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AITA for not inviting my mom to my wedding be...</td>\n",
       "      <td>I (28M) am getting married in a few months to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIT for telling my parents something my friend...</td>\n",
       "      <td>I've told this story in a few other subreddits...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AITA -</td>\n",
       "      <td>throw away account so no one sees..\\n\\nMy \\[24...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AITA - my 20 year old flatmate asks me questio...</td>\n",
       "      <td>For context I’m 33; and my flatmate is 20.\\nSh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AITA - my husband never let's me sleep in, so ...</td>\n",
       "      <td>As the title states, I wake my husband up ever...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   AITA for not inviting my mom to my wedding be...   \n",
       "1  AIT for telling my parents something my friend...   \n",
       "2                                            AITA -    \n",
       "3  AITA - my 20 year old flatmate asks me questio...   \n",
       "4  AITA - my husband never let's me sleep in, so ...   \n",
       "\n",
       "                                            selftext  aitah_tag  \n",
       "0  I (28M) am getting married in a few months to ...          0  \n",
       "1  I've told this story in a few other subreddits...          0  \n",
       "2  throw away account so no one sees..\\n\\nMy \\[24...          0  \n",
       "3  For context I’m 33; and my flatmate is 20.\\nSh...          0  \n",
       "4  As the title states, I wake my husband up ever...          0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training and testing dataset\n",
    "selftext_train, selftext_test, aitah_tag_train, aitah_tag_test = train_test_split(df2['selftext'], df2['aitah_tag'], test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for FastText\n",
    "def format_for_fasttext(texts, labels, filepath):\n",
    "    with open(filepath, 'w') as f:\n",
    "        for text, label in zip(texts, labels):\n",
    "            f.write(f\"__label__{label} {text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training and testing data\n",
    "format_for_fasttext(selftext_train, aitah_tag_train, \"train_fasttext.txt\")\n",
    "format_for_fasttext(selftext_test, aitah_tag_test, \"test_fasttext.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  16306\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread: 2240219 lr:  0.000000 avg.loss:  0.291151 ETA:   0h 0m 0s100.0% words/sec/thread: 2241376 lr: -0.000415 avg.loss:  0.291151 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "ft_model = fasttext.train_supervised(input=\"train_fasttext.txt\", epoch=25, lr=1.0, wordNgrams=2, verbose=2)\n",
    "\n",
    "# Save the trained model for later use\n",
    "ft_model.save_model(\"fasttext_aitah_model.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This is overfitting na"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "result = ft_model.test(\"test_fasttext.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173, 0.9017341040462428, 0.9017341040462428)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.90\n",
      "Recall: 0.90\n",
      "Number of examples: 173\n"
     ]
    }
   ],
   "source": [
    "# Output results\n",
    "print(f\"Precision: {result[1]:.2f}\")\n",
    "print(f\"Recall: {result[2]:.2f}\")\n",
    "print(f\"Number of examples: {result[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a label map\n",
    "label_map = {#\n",
    "    \"__label__0\": \"Not the Asshole\",\n",
    "    \"__label__1\": \"The Asshole\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: Not the Asshole, Confidence: 0.98\n",
      "Predicted Label: The Asshole, Confidence: 0.02\n"
     ]
    }
   ],
   "source": [
    "# Predict top-k labels (e.g., top 2)\n",
    "predicted_labels, confidences = ft_model.predict(\"Am I the asshole for yelling at my neighbor?\", k=2)\n",
    "\n",
    "# Display all predictions\n",
    "for label, confidence in zip(predicted_labels, confidences):\n",
    "    human_readable_label = label_map[label]\n",
    "    print(f\"Predicted Label: {human_readable_label}, Confidence: {confidence:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "3.10.14",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
